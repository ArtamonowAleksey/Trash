{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df = pd.read_csv('Bike_Sharing_Train.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "with pd.ExcelWriter('test.xlsx', engine='openpyxl') as writer:\n",
    "    writer.book = load_workbook('test.xlsx')\n",
    "    df.to_excel(writer, 'DATA',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas code\n",
    "top10_engagements_pandas = daily_engagements[['acct', 'total_minutes_visited', 'utc_date']]\n",
    "                              .sort('total_minutes_visited', ascending = False)[:10]\n",
    "\n",
    "# pandasql code\n",
    "simple_query = '''\n",
    "    SELECT \n",
    "        acct, \n",
    "        total_minutes_visited,\n",
    "        utc_date\n",
    "    FROM daily_engagements \n",
    "    ORDER BY total_minutes_visited desc\n",
    "    LIMIT 10\n",
    "    '''\n",
    "top10_engagements_pandas = ps.sqldf(simple_query, locals())\n",
    "\n",
    "# pandas code\n",
    "weekday_engagement_pandas = pd.DataFrame(daily_engagements.groupby('weekday').total_minutes_visited.mean())\n",
    "\n",
    "# pandasql code\n",
    "aggr_query = '''\n",
    "    SELECT \n",
    "        avg(total_minutes_visited) as total_minutes_visited,\n",
    "        weekday\n",
    "    FROM daily_engagements \n",
    "    GROUP BY weekday\n",
    "    '''\n",
    "weekday_engagement_pandasql = ps.sqldf(aggr_query, locals()).set_index('weekday')\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_sql.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as offline\n",
    "from plotly.graph_objs import *\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "#Средняя зарплата от занимаемой позиции\n",
    "graph1 = Bar(\n",
    "            x=data2.index,\n",
    "            y=data2['Mean Wage'],\n",
    "            name='Средняя ЗП'\n",
    "    )\n",
    "graph2=Bar(\n",
    "            x=data2.index,\n",
    "            y=data2['Count'],\n",
    "            name='Колличество игроков'\n",
    "    \n",
    "    )\n",
    "\n",
    "layout = Layout(\n",
    "    title='Распределение средней ЗП и Количество игроков',\n",
    "    yaxis=dict(\n",
    "        title='Средняя ЗП и количество игроков'\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title='Позиция')\n",
    "    \n",
    ")\n",
    "final_graph = [graph1,graph2]\n",
    "fig = Figure(data=final_graph, layout=layout)\n",
    "offline.iplot(fig)\n",
    "\n",
    "\n",
    "# Рисуем График\n",
    "trace = Scatter(\n",
    "    x = data['Age'],\n",
    "    y = data['Normal Value'],\n",
    "    name = 'Стоимость',\n",
    "    mode = 'markers',\n",
    "    \n",
    "    marker = dict(\n",
    "        size = 10,\n",
    "        color = 'rgba(255, 182, 193, .9)',\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "layout = Layout(\n",
    "    title='Распределение Возраста от стоимости ',\n",
    "    yaxis=dict(\n",
    "        title='Стоимость'\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title='Возраст')\n",
    "    \n",
    ")\n",
    "graph = [trace]\n",
    "fig = Figure(data=graph, layout=layout)\n",
    "#fig = dict(data=graph, layout=layout)\n",
    "offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.qcut()\n",
    "#Рсаскраска таблицы\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config['DEFAULT'] = {'token': '2055134425:AAFAwg2C1KGHzhYflG0ciHlAJEFAKWcio9Q',\n",
    "                    'path_to_page': 'C:/Users/artam/OneDrive/Рабочий стол/Projects/Stocks/Scripts/stocks-project/page.jpg',\n",
    "                    'path_to_excel': 'C:/Users/artam/OneDrive/Рабочий стол/Projects/Stocks/Scripts/stocks-project/From Python.xlsx'}\n",
    "\n",
    "with open('C:/Users/artam/OneDrive/Рабочий стол/Projects/Stocks/Scripts/stocks-project/config.ini', 'w') as configfile:\n",
    "    config.write(configfile)\n",
    "\n",
    "def highlight_max(s):\n",
    "    return ['background-color: yellow' if x==0 else 'background-color: grey' for x in final['Days to market']]\n",
    "\n",
    "html = final.style.apply(highlight_max).render()\n",
    "\n",
    "#Расскраска таблицы\n",
    "total_id = 'totalID'\n",
    "header_id = 'headerID'\n",
    "data_in_html = final.to_html()\n",
    "style_in_html = \"\"\"<style>\n",
    "    table#{total_table} {{color='black';font-size:13px; text-align:center; border:0.2px solid black;\n",
    "                         border-collapse:collapse; table-layout:fixed; height=\"250\"; text-align:center }}\n",
    "    thead#{header_table} {{background-color: #4D4D4D; color:#ffffff}}\n",
    "    </style>\"\"\".format(total_table=total_id, header_table=header_id)\n",
    "data_in_html = re.sub(r'<table', r'<table id=%s ' % total_id, data_in_html)\n",
    "data_in_html = re.sub(r'<thead', r'<thead id=%s ' % header_id, data_in_html)\n",
    "HTML(style_in_html+data_in_html)\n",
    "df_stocks[df_stocks.name.isin(['Southwestern Energy', 'Ford','Endo International PLC'])]\n",
    "enumerate\n",
    "[y-x for x, y in zip(Test['dt'][:-1], Test['dt'][1:])]\n",
    "c = [x+dt.timedelta(days=y) for x,y in zip(a,b)] \n",
    "np.diff()\n",
    "object_columns = X.select_dtypes(['object']).columns\n",
    "Df.head(3)\n",
    "Df.columns\n",
    "df_filter = df['ID'].isin(['A001','C022',...])\n",
    "dt.datetime.strptime('2019-11-12 22:56:00','%Y-%m-%d %H:%M:%S').date()\n",
    "df['dt'] = pd.to_datetime(df['dt'], errors='coerce')\n",
    "numbers = [2, 3, 4, 5, 6]\n",
    "reduce(lambda res, x: res*x, numbers, 1)\n",
    "nunique\n",
    "fin['k'] = [1 if x==y else 0 for x,y in zip(fin['Toaday'],fin['Следующая покупка'])]\n",
    "fin['Следующая покупка'] = [x+dt.timedelta(days=y) for x,y in zip(fin['Дата'],fin['Дельта'])] \n",
    "yesterday.strftime('%Y-%m-%d')\n",
    "df['year month'] = [str(dt.datetime.strptime(dt.datetime.strftime(x,'%Y-%m-%d') ,'%Y-%m-%d').year)+ \\\n",
    "           str(dt.datetime.strptime(dt.datetime.strftime(x,'%Y-%m-%d') ,'%Y-%m-%d').month) for x in df['dt']]\n",
    "Table['Lots']=[math.trunc(i) for i in Table['Lots']]\n",
    "#df.iloc[:,0:100]\n",
    "#https://towardsdatascience.com/pandas-tips-and-tricks-33bcc8a40bb9\n",
    "#Df.describe\n",
    "#Df.sort_values(by='count', ascending=False)\n",
    "#Df.groupby(['season','count']).sum()\n",
    "#Df_1 = Df[['season','count']]\n",
    "#Df_1.groupby(['season']).sum(level='count').sort_values(by='season',ascending=False)\n",
    "#Df[['season','count']].groupby(['season']).sum(level='count').sort_values(by='season',ascending=False)\n",
    "#Df.info()\n",
    "#Df.describe()\n",
    "#Df[(Df['season']==1)&(Df['casual']==0)]\n",
    "#Df.describe(include=[np.object])\n",
    "#Df['season'].value_counts()\n",
    "#Df.corr()\n",
    "#df_test=df_support_tickets.groupby(['Start Month','ticket_category'])['ticket_category'].aggregate('count').unstack()\n",
    "#Df.sample(frac=0.1)\n",
    "#Df_1.groupby(['season']).groups\n",
    "#Df_1.groupby(['season']).first()\n",
    "#Df_1.groupby(['season'])[['count']].mean()\n",
    "#Df_1.groupby(['season']).agg({'windspeed':[sum,min],'datetime':'first'})\n",
    "#Df_1.groupby(['season']).agg({'windspeed':lambda x:max(x)+,'datetime':'first'})\n",
    "#season = {'1':10,'2':200}\n",
    "#Df['season'].map(season).head()\n",
    "#Df.apply(min)\n",
    "#Df['windspeed'].apply(lambda x:x/60)\n",
    "#Df.apply(lambda x:x['windspeed']/60,axis=1)\n",
    "#data.fillna(0)\n",
    "#df['col3'] = df.apply(lambda row: row[1] if row[0] > row[1] else row[0], axis=1)\n",
    "#data['col']=data['Age'].apply(lambda x: 1 if x<30 else 0)\n",
    "#data['col']=data.apply(lambda x: 1 if x['Age']<30 and x['Nationality']=='Russia' else 0,axis=1)\n",
    "#data.drop(labels='Column',axis=1)\n",
    "#Data2['Value2']=Data2['Value'].str.strip('€MK')\n",
    "#data['Classification Age'] = np.where(data['Age']>=30,'yes','no')\n",
    "#df_filter = df['ID'].isin(['A001','C022',...])\n",
    "#[(data['Preferred Positions'].str.contains('^GK', na=False))]\n",
    "#Data2.groupby(Data2['Nationality'])[['Overall']].mean().join(Data2.groupby(Data2['Nationality'])[['Potential']].mean())\n",
    "#data[['Nationality','Name','Club','Age','Overall','Potential','Value']][(data['Overall']>75)&(data['Nationality']=='Russia')&(data['Preferred Positions'].str.contains('^GK', na=False))].sort_values(by='Age')\n",
    "#date=pd.to_datetime(d).time()\n",
    "#ST = {'M':1000000,'K':1000,'0':0}\n",
    "#Data2['Normal Price']=pd.to_numeric(Data2['Value'].str[-1::].map(ST))*pd.to_numeric(Data2['Value'].str.strip('€MK'))\n",
    "#Df_1[['tripduration']].notnull()\n",
    "#Df_1[(Df_1['start station id'])==(Df_1['end station id'])].count()\n",
    "#Df_1['bikeid'].groupby(by=Df_1['tripduration']).max()\n",
    "#Df_1.groupby(['bikeid']).agg({'bikeid':['count']})\n",
    "#Df_1['bikeid'].value_counts()\n",
    "#Df_1.groupby(['bikeid'])['tripduration'].max()\n",
    "#Df_1.groupby(['bikeid']).agg({'tripduration':'max'})\n",
    "#Df_1['start station id'].isnull().sum()\n",
    "#Df_1.groupby(['usertype']).agg({'tripduration':'mean'})\n",
    "#Df_1['tripduration'].mean()\n",
    "#Df_1.info\n",
    "#Df_Test = Df_1.sample(frac=0.1)\n",
    "#data['col']=data.apply(lambda x: 1 if x['Age']<30 and x['Nationality']=='Russia' else 0,axis=1)\n",
    "# from collections import Counter\n",
    " \n",
    "# a = Counter('superfluous')\n",
    " \n",
    "# # Counter({'u': 3, 's': 2, 'e': 1, 'l': 1, 'f': 1, 'o': 1, 'r': 1, 'p': 1})\n",
    "# print(a)\n",
    " \n",
    "# counter = Counter('superfluous')\n",
    "# print(counter['u']) # 3\n",
    "#taxi_mex[’month’] = taxi_mex[’pickup_datetime’].dt.month\n",
    "thisXMasDayAsString = weekDays[thisXMasDay]\n",
    "print(\"This year's Christmas is on a {}\".format(thisXMasDayAsString))\n",
    "\n",
    "df['Control'] = ['P' if x in Cat_positive else 'N' if x in Cat_negative else 'T' for x in df['Категория']]\n",
    "Donut\n",
    "labels = K['Name_2']\n",
    "sizes = K['sum']\n",
    "colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral']\n",
    "#explode = (0, 0, 0, 0,0, 0, 0, 0,0,0)  # explode a slice if required\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.pie(sizes,  labels=labels, colors=colors,\n",
    "        autopct='%1.1f%%', shadow=True)\n",
    "        \n",
    "#draw a circle at the center of pie to make it look like a donut\n",
    "centre_circle = plt.Circle((0,0),0.85,color='black', fc='white',linewidth=1)\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "\n",
    "# Set aspect ratio to be equal so that pie is drawn as a circle.\n",
    "plt.axis('equal')\n",
    "plt.show()  \n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=final.columns,\n",
    "                line_color='darkslategray',\n",
    "                fill_color='lightskyblue',\n",
    "                align='left'),\n",
    "    cells=dict(values=[final['Категория'],\n",
    "               final['Дата'],\n",
    "               final['Кол-во'],\n",
    "               final['Сумма'],\n",
    "               final['Сумма.шт'],\n",
    "               final['Дельта'],\n",
    "               final['Days to market'],\n",
    "               final['Следующая покупка']],\n",
    "               line_color='darkslategray',\n",
    "               fill_color='lightcyan',\n",
    "               align='left'))\n",
    "])\n",
    "\n",
    "fig.update_layout(width=900, height=300)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "def barplot(x_data, y_data, x_label=\"\", y_label=\"\", title=\"\"):\n",
    "    _, ax = plt.subplots()\n",
    "\n",
    "    ax.bar(x_data, y_data, color = '#539caf', align = 'center')\n",
    "\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "barplot(df['year month'],df['sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  SciPy Stats Models SkLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.proportion as smp\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "#Ноутбуки по статистике \n",
    "#https://sebastianraschka.com/notebooks/python-notebooks.html\n",
    "#https://seeing-theory.brown.edu/basic-probability/index.html\n",
    "#Расчет доверительного интервала\n",
    "smp.proportion_confint(Sum_Converted,Len_Sample,alpha=0.05,method = 'normal')\n",
    "#Расчет статистики Стьюдента\n",
    "stats.ttest_ind(df['converted'][df['group']=='A'],df['converted'][df['group']=='B'],equal_var=False)\n",
    "#Функция Распределения\n",
    "rv_uniform.cdf(5.5)\n",
    "#Плотность вероятности\n",
    "rv_uniform.pdf(7)\n",
    "#Создание массива значений\n",
    "X = np.linspace(a - 2, b + 2, 100)\n",
    "#Нормальное распределение\n",
    "mu = 2 -- среднее значение sigma = 0.5 - среднеквадратичное отклонение\n",
    "rv_norm = stats.norm(loc=mu, scale=sigma)\n",
    "#Сэмпл из распределения \n",
    "sample_size = 100 sample = np.random.choice(a = population, size = sample_size\n",
    "#Расчет Z-Value для Стьюдента \n",
    "z_value = stats.norm.ppf(q = 0.975) print(\"z-value:\", z_value)\n",
    "                                            \n",
    "                                            \n",
    "#https://scikit-learn.org/stable/modules/linear_model.html     \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, random_state=54, test_size=0.33)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "scores = []\n",
    "coef = []\n",
    "for alpha in range(10, 100, 10):\n",
    "    model = Ridge(alpha=alpha, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse_score = mean_squared_error(y_test, y_pred)\n",
    "    scores.append(mse_score)\n",
    "    coef.append(alpha)\n",
    "index = np.array(scores).argmin()\n",
    "answer1 = coef[index]\n",
    "answer2 = round(scores[index], 3)\n",
    "                                            \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(coef, scores, '--o')\n",
    "plt.title(\"MSE(alpha)\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"mean squared error, 1000$'s\")\n",
    "plt.show()\n",
    "                                            \n",
    "                                            \n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(random_state=42)\n",
    "model.fit(diabetes.data, diabetes.target)\n",
    "\n",
    "numFeatures = len(diabetes.feature_names)\n",
    "answer3 = float(numFeatures - list(model.coef_).count(0)) / numFeatures\n",
    "answer3 = round(answer3, 1)\n",
    "                                            \n",
    "model = Lasso(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse_score = mean_squared_error(y_test, y_pred)\n",
    "answer4 = round(mse_score, 3)\n",
    "print(\"mse error(ridge) < mse error(lasso) ? {}\".format(answer2 < answer4))\n",
    "                                            \n",
    "                                            \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "X = data[data.columns[:-1]].as_matrix()\n",
    "y = np.array(data['target'])\n",
    "                                            \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "model = Ridge(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "score = mean_squared_error(y_test, y_pred)\n",
    "answer1 = round(score, 2)\n",
    "                                            \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_norm = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.33, random_state=42)\n",
    "model = Ridge(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "score = mean_squared_error(y_test, y_pred)\n",
    "answer2 = round(score, 2)\n",
    "                                            \n",
    "                                            \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def get_score(model_cls, **kwargs):\n",
    "    model = model_cls(**kwargs)\n",
    "    cv = StratifiedKFold(4)\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "    return round(scores.mean(), 3)\n",
    "\n",
    "random_forest_scores = []\n",
    "for n_estimators in (1, 5, 10, 20):\n",
    "    score = get_score(RandomForestClassifier, n_estimators=n_estimators, random_state=42)\n",
    "    random_forest_scores.append(score)\n",
    "\n",
    "answer1 = max(random_forest_scores)\n",
    "                                            \n",
    "                                            \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "gradient_boosting_score = get_score(GradientBoostingClassifier, random_state=42)\n",
    "logistic_regression_score = get_score(LogisticRegression)\n",
    "\n",
    "if gradient_boosting_score < logistic_regression_score:\n",
    "    model_name = \"Logistic Regression\"\n",
    "    answer2 = logistic_regression_score\n",
    "else:\n",
    "    model_name = \"Gradient Boosting\"\n",
    "    answer2 = gradient_boosting_score\n",
    "\n",
    "print(\"best score: %s\" % model_name)\n",
    "                                            \n",
    "boston = load_boston()\n",
    "models = [Ridge, Lasso, RandomForestRegressor, GradientBoostingRegressor]\n",
    "model_names = ['Ridge', 'Lasso', 'RandomForestRegressor', 'GradientBoostingRegressor']\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, random_state=54, test_size=0.33)\n",
    "\n",
    "def estimate_model(model_cls):\n",
    "    model = model_cls(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test, y_pred)\n",
    "    return score\n",
    "\n",
    "regression_scores = []\n",
    "for model_cls in models:\n",
    "    score = estimate_model(model_cls)\n",
    "    regression_scores.append(score)\n",
    "\n",
    "index = np.array(regression_scores).argmin()\n",
    "answer3 = regression_scores[index]\n",
    "print(\"best score: %s\" % model_names[index])\n",
    "                                            \n",
    "                                            \n",
    "                                            \n",
    "TP = np.sum(np.logical_and(df['prediction']== 1, df['target']  == 1))\n",
    " \n",
    "# True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "TN = np.sum(np.logical_and(df['prediction']== 0, df['target']  == 0))\n",
    " \n",
    "# False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "FP = np.sum(np.logical_and(df['prediction']== 1, df['target']  == 0))\n",
    " \n",
    "# False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "FN = np.sum(np.logical_and(df['prediction']== 0, df['target']  == 1))\n",
    "\n",
    "print('TP: %i, FP: %i, TN: %i, FN: %i' % (TP,FP,TN,FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy MatplotLib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[2,-1,0],[0,1,3],[4,-3,-3]])\n",
    "linalg.det(X)\n",
    "X=np.array([[1,13],[2,3]])\n",
    "linalg.det(X)\n",
    "X_1 = np.array([[42,1,6],[1,0,-3],[3,5,1]])\n",
    "X_2 = np.array([[-1,1],[0,7],[9,-2]])\n",
    "X_1*X_2\n",
    "\n",
    "K = np.array([[2,1,-3],[1,0,0],[1,0,1]])\n",
    "linalg.inv(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([[2,1,-3],[1,0,0],[1,0,1]])\n",
    "linalg.inv(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=np.array([[0,3],[3,8]])\n",
    "eigenvalues, eigenvectors = linalg.eig(K)\n",
    "print(eigenvalues, eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[2,-1,0],[1,1,3],[4,-3,-3]])\n",
    "linalg.det(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = np.array([[0,9,19,13],[1,20,5,13],[12,11,3,4]])\n",
    "X_2 = np.array([[2,0,0,0],[1,2,2,0],[2,1,1,0],[0,0,1,1]])\n",
    "np.dot(X_1,X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.array([[-1,33,4,1],[0,1,1,0]])\n",
    "b.flatten().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=np.array([[6,0,3],[0,-1,2],[12,3,0]])\n",
    "linalg.det(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=np.array([[1,-1,-1,0],[-1,2,-1,-1],[-1,-1,2,-1],[0,-1,-1,1]])\n",
    "eigenvectors = linalg.eig(L)\n",
    "print(eigenvalues, eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = np.array([[2,4,0,4,1],[2,4,1,1,0],[1,1,1,2,2],[0,1,3,2,3],[2,2,2,0,2]])\n",
    "K=linalg.inv(O)\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=np.array([[1,1,1,1,1]])\n",
    "l=np.array([[2,2,2,2,2]])\n",
    "np.multiply(k,l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=np.array([92,13,44,555,1,-3])\n",
    "k.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy.random import exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'x':range(20),'y':exponential(10,20)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = exponential(5,20)\n",
    "data2 = exponential(6,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(data2)),data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data1,label='Первый игрок')\n",
    "plt.scatter(range(len(data2)),data2,color='red',label='Второй игрок')\n",
    "plt.title('Результаты',fontdict={'fontsize':20})\n",
    "plt.xlabel('Номер попытки')\n",
    "plt.ylabel('Результат')\n",
    "plt.legend()\n",
    "plt.xticks(range(0,20,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('results.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots()\n",
    "axes.plot(exponential(5,20))\n",
    "axes.set_title('График')\n",
    "fig,axes = plt.subplots(nrows=2,ncols=3,figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(nrows=2,ncols=3,figsize=(10,5))\n",
    "for row, row_axes in enumerate(axes):\n",
    "    for column ,ax in enumerate(row_axes):\n",
    "        ax.plot(exponential(column,20))\n",
    "        ax.set_title('Холст колонка {} cтрока {}'.format(column+1,row+1))\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_titanic.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df.Fare.plot.hist(bins=5)\n",
    "df.Fare.plot.kde()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='Fare',y='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Survived').Fare.plot.kde()\n",
    "plt.xlim(0,200)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=df.Fare.plot.hist()\n",
    "ax.set_title('Vizualization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
